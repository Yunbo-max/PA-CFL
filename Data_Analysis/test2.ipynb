{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding = utf-8 -*-\n",
    "# @time:08/07/2023 00:49\n",
    "# Author:Yunbo Long\n",
    "# @File:data_processing.py\n",
    "# @Software:PyCharm\n",
    "# -*- coding = utf-8 -*-\n",
    "# @time:03/07/2023 13:11\n",
    "# Author:Yunbo Long\n",
    "# @File:CNN_local.py\n",
    "# @Software:PyCharm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict\n",
    "from sklearn import svm,metrics,tree,preprocessing,linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.linear_model import Ridge,LinearRegression,LogisticRegression,ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier, GradientBoostingRegressor,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error,recall_score,confusion_matrix,f1_score,roc_curve, auc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Hiding the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# Load dataset\n",
    "# dataset = pd.read_csv('/content/drive/My Drive/DataCoSupplyChainDataset.csv')\n",
    "\n",
    "dataset =pd.read_csv('/Users/yunbo/Documents/GitHub/PFL_Optimiozation/Data/DataCoSupplyChainDataset.csv',encoding='iso-8859-1')\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "# print(dataset.head(30))\n",
    "\n",
    "\n",
    "dataset['Customer Full Name'] = dataset['Customer Fname'].astype(str) + dataset['Customer Lname'].astype(str)\n",
    "dataset['TotalPrice'] = dataset['Order Item Quantity'] * dataset[\n",
    "    'Sales per customer']  # Multiplying item price * Order quantity\n",
    "\n",
    "\n",
    "\n",
    "data = dataset.drop(\n",
    "    ['Customer Email', 'Customer Id', 'Customer Password', 'Customer Fname', 'Customer Lname',\n",
    "      'Product Description', 'Product Image', 'Order Zipcode','Product Status','Order Profit Per Order','Product Price'], axis=1)\n",
    "\n",
    "data['Customer Zipcode'] = data['Customer Zipcode'].fillna(0)  # Filling NaN columns with zero\n",
    "\n",
    "\n",
    "\n",
    "data['order_year'] = pd.DatetimeIndex(data['order date (DateOrders)']).year\n",
    "data['order_month'] = pd.DatetimeIndex(data['order date (DateOrders)']).month\n",
    "data['order_week_day'] = pd.DatetimeIndex(data['order date (DateOrders)']).day_name()\n",
    "data['order_hour'] = pd.DatetimeIndex(data['order date (DateOrders)']).hour\n",
    "# data['order_second'] = pd.DatetimeIndex(data['order date (DateOrders)'])\n",
    "\n",
    "data['shipping_year'] = pd.DatetimeIndex(data['shipping date (DateOrders)']).year\n",
    "data['shipping_month'] = pd.DatetimeIndex(data['shipping date (DateOrders)']).month\n",
    "data['shipping_week_day'] = pd.DatetimeIndex(data['shipping date (DateOrders)']).day_name()\n",
    "data['shipping_hour'] = pd.DatetimeIndex(data['shipping date (DateOrders)']).hour\n",
    "\n",
    "\n",
    "label_data = data[['Order Region','shipping_week_day','order_week_day','Customer Full Name','Type','Delivery Status','Category Name','Customer City','Customer Country','Customer Segment','Customer State','Customer Street','Department Name','Market','Order City','Order Country','order date (DateOrders)','Order State','Order Status','Product Name','shipping date (DateOrders)','Shipping Mode']]\n",
    "\n",
    "data['index'] = data['Order Region']\n",
    "#\n",
    "\n",
    "\n",
    "target=data['Sales']\n",
    "\n",
    "data=data.drop(columns=['shipping_week_day','order_week_day','Customer Full Name','Sales','Type','Delivery Status','Category Name','Customer City','Customer Country','Customer Segment','Customer State','Customer Street','Department Name','Market','Order City','Order Country','order date (DateOrders)','Order State','Order Status','Product Name','shipping date (DateOrders)','Shipping Mode','Order Region','Sales per customer'])\n",
    "\n",
    "\n",
    "def Labelencoder_feature(x):\n",
    "    le=LabelEncoder()\n",
    "    x=le.fit_transform(x)\n",
    "    return x\n",
    "\n",
    "# Exclude datetime columns from label encoding\n",
    "# datetime_columns = ['order date (DateOrders)', 'shipping date (DateOrders)']\n",
    "# data_encoded = data.drop(datetime_columns, axis=1)\n",
    "\n",
    "# Apply label encoding to remaining columns\n",
    "data_encoded = label_data.apply(Labelencoder_feature)\n",
    "\n",
    "data = pd.concat([data_encoded, data], axis=1)\n",
    "\n",
    "\n",
    "# # Calculate correlation matrix\n",
    "# correlation_matrix = data.corr()\n",
    "\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "# print(data.head(100))\n",
    "# print(data.shape)\n",
    "\n",
    "# Create heatmap\n",
    "# plt.figure(figsize=(100, 50))\n",
    "# sns.heatmap(correlation_matrix, annot=True, fmt=\".3f\", cmap=\"BuPu\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "data_final=data[['Order Id', 'Order Customer Id', 'Order Item Id',\n",
    " 'Order Item Product Price' ,'Department Id', 'Order Item Quantity',\n",
    " 'Category Id' ,'shipping_month' ,'Benefit per order' ,'Order Item Total',\n",
    " 'Product Card Id', 'Product Name', 'Order Item Cardprod Id' ,\n",
    " 'Order State', 'Product Category Id', 'order_week_day', 'shipping_year',\n",
    " 'Category Name', 'order_month', 'order_year' ,'Order Item Discount',\n",
    " 'Department Name', 'Market', 'TotalPrice', 'Order City',\n",
    " 'Days for shipment (scheduled)' ,'Customer Segment', 'Customer Full Name','index']]\n",
    "\n",
    "train_data = data_final\n",
    "xs=train_data.loc[:, train_data.columns != 'Sales']\n",
    "ys=target\n",
    "xs_train, xs_test,ys_train,ys_test = train_test_split(xs,ys,test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Concatenate train_data and ys\n",
    "train_data['Sales'] = ys.values\n",
    "\n",
    "# Save the integrated DataFrame to CSV\n",
    "train_data.to_csv('integrated_train_data_ISMM_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
